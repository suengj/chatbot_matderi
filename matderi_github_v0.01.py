# ë§›ëŒ€ë¦¬ v0.0.1
# suengjae hong

#pip install tabulate

from dotenv import load_dotenv

import os, json, time, requests
from datetime import datetime
import pandas as pd
import numpy as np # numpy==1.26.4
import altair as alt
# import plotly.express as px # a terse and high-level API for creating figures
import streamlit as st

from wordcloud import WordCloud
import matplotlib.pyplot as plt

#Langchain only
from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI
from langchain.callbacks import StreamlitCallbackHandler

### í•¨ìˆ˜ Setup
# word cloud dataframe
def transform_to_value_count(df, column_name):
    """
    Transforms a DataFrame with a column of comma-separated values 
    into a value-count DataFrame.

    Parameters:
        df (pd.DataFrame): Input DataFrame with one column containing comma-separated values.
        column_name (str): Name of the column to process.

    Returns:
        pd.DataFrame: A DataFrame with unique values and their counts.
    """
    # Step 1: Ensure the column exists
    if column_name not in df.columns:
        raise ValueError(f"Column '{column_name}' does not exist in the DataFrame.")
    
    # Step 2: Split and explode the column
    exploded_series = df[column_name].str.split(',').explode().str.strip()
    
    # Step 3: Count the occurrences
    value_counts = exploded_series.value_counts().reset_index()
    value_counts.columns = [column_name, 'count']
    
    return value_counts

### SETTING ###
## API ###
load_dotenv()
default_api_key = os.environ.get('OPENAI_API_KEY')

## Dataframe ###
FILE_PATH = 'https://raw.githubusercontent.com/suengj/chatbot_matderi/refs/heads/main/yeoeuido_matzip.csv'
df = pd.read_csv(f'{FILE_PATH}')

## FONT ###
FONT_PATH = 'https://raw.githubusercontent.com/suengj/chatbot_matderi/refs/heads/main/NanumGothicLight.ttf'
FONT_LOCAL_PATH = "NanumGothicLight.ttf"

def ensure_font_downloaded(font_url, local_path):
    if not os.path.exists(local_path):
        st.info("Downloading font file. Please wait...")
        response = requests.get(font_url)
        if response.status_code == 200:
            with open(local_path, "wb") as f:
                f.write(response.content)
        else:
            raise Exception(f"Failed to download font file: {font_url}")

# ì›¹ ëŒ€ì‹œë³´ë“œ ê°œë°œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ ìŠ¤íŠ¸ë¦¼ë¦¿ì€ main í•¨ìˆ˜ê°€ ìˆì–´ì•¼ í•œë‹¤.
def main():

    st.set_page_config(
        page_title = "ë™ì—¬ì˜ë„ ë§›ëŒ€ë¦¬",
        page_icon = "ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded")

    ## ë©”ì‹œì§€ ####
    st.title('ë™ì—¬ì˜ë„ ë§›ì¸í„´_v0.0.1')
    st.header('ChatGPT ê¸°ë°˜ ë™ì—¬ì˜ë„ ë§›ì§‘ DB ê²€ìƒ‰ ë´‡ì…ë‹ˆë‹¤')

    # Side ì°½
    st.sidebar.title('í•„í„° ì…ë ¥ì°½')
    st.sidebar.subheader("ë³„ë„ Open AI API KEY ì…ë ¥ì‹œ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")

    _usr_key = st.sidebar.text_input('ë¯¸ì…ë ¥ì‹œ ê¸°ë³¸ ì œê³µ: GPT 3.5 turbo',
                                     value = "",
                                     type='password') # ë¯¸ì…ë ¥ì‹œ ë‚˜ì˜ APIë¡œ default ì²˜ë¦¬ í•„ìš”

    _usr_key_to_use = default_api_key if _usr_key == "" else _usr_key

    _usr_rate = st.sidebar.number_input('5ì  ë§Œì  ì¤‘ í‰ì  ì…ë ¥',
                                        min_value = 0.0,
                                        max_value = 5.0) # ìˆ˜ì¹˜ ì •ë³´ ì…ë ¥

    # _usr_voc = st.sidebar.text_input('ì›í•˜ëŠ” VOC ë‚´ìš©ì„ ì…ë ¥ í•˜ì„¸ìš”') # í˜„ì¬ ê¸°ëŠ¥ updating
    # _usr_select = st.sidebar.multiselect('ì£¼ìš” í‚¤ì›Œë“œ ì„ íƒ', ['', 'í˜¼ë°¥', 'ë°ì´íŠ¸', 'ë¬´ë£Œì£¼ì°¨']) # updating

    MODEL_LST = ['gpt-3.5-turbo'] if _usr_key_to_use == default_api_key else ['gpt-4o-2024-08-06','gpt-4o-mini-2024-07-18',
                                                                              'o1-mini-2024-09-12','o1-2024-12-17',
                                                                              'gpt-3.5-turbo']

    _usr_model = st.sidebar.selectbox('ì„ íƒí•  AI ëª¨ë¸', MODEL_LST)

    # _usr_temperature = st.sidebar.slider('ì°½ì˜ì  ì‘ë‹µì´ í•„ìš”í•˜ë‹¤ë©´ 1ì— ê°€ê¹ê²Œ ì˜®ê¸°ì„¸ìš”',
    #                                      0.0, 1.0, (0.2))
    _usr_temperature = 0.0

    st.sidebar.subheader("version history")

    text_history = """
    **2024-12-20**: ë§›ì¸í„´ 0.0.1. ë²„ì ¼ ì‘ì„±
    """
    st.sidebar.markdown(text_history)


    # ìµœì¢… ì„ íƒ DB : í•„í„°ë§ ì ìš©
    df['í‰ì '] = pd.to_numeric(df['í‰ì ']).fillna(0)

    new_df = df[(df['í‰ì '] >= _usr_rate)]


    ## Agent MODEL & Messages
        
    # Chat AGENT ì„¤ì •
    LLM_MODEL = ChatOpenAI(
        temperature=_usr_temperature,
        max_tokens = 500,
        model=_usr_model,
        openai_api_key = _usr_key_to_use
    )
    
    # ìµœì´ˆ ì‘ë‹µì´ ì—†ì„ ê²½ìš°, ë°˜í™˜í•˜ëŠ” ë‚´ìš©
    if "messages" not in st.session_state or st.sidebar.button("clear conversation history"):
        st.session_state["messages"] = [{"role":"assistant","content":"ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”"}]

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input(placeholder="ì›í•˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.chat_message("user").write(prompt)

    if not _usr_key_to_use:
        st.info("Please add your OpenAI API key to continue.")
        st.stop()

    agent = create_pandas_dataframe_agent(
        LLM_MODEL,    	# ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©
        new_df,                                	# ë°ì´í„°í”„ë ˆì„
        verbose=False,                      	# ì¶”ë¡ ê³¼ì • ì¶œë ¥
        agent_type=AgentType.OPENAI_FUNCTIONS, # AgentType.ZERO_SHOT_REACT_DESCRIPTION
        agent_executor_kwargs={"handle_parsing_errors": True},
        allow_dangerous_code=True
    )

    with st.chat_message("assistant"):
        st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)
        response = agent.run(st.session_state.messages, callbacks=[st_cb])
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(response)


    # separate columns
    col1,col2 = st.columns([2,1])
    
    with col1:
        
        with st.expander('í´ë¦­í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ë³´ê¸°') :
            st.dataframe(new_df)

    with col2:
    
        # word cloud
        # Convert the DataFrame to a dictionary
        _wc_data = transform_to_value_count(new_df, 'í‚¤ì›Œë“œ')
        
        wc_dic = dict(zip(_wc_data['í‚¤ì›Œë“œ'], _wc_data['count']))
        
        # Generate the Word Cloud
        wc = WordCloud(
            font_path=FONT_LOCAL_PATH,
            width=800, height=400, background_color='white').generate_from_frequencies(wc_dic)

        
        # Display the Word Cloud
        st.write("### ì‹ë‹¹ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        st.pyplot(fig)



if __name__ == '__main__' :
	main()

# end of the code
